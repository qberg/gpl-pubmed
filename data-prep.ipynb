{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":["OsxglCQIzap7"],"authorship_tag":"ABX9TyNYMu8loynVXU7AtF2k2bin"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"6oFM2ksF266j"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)"]},{"cell_type":"code","source":["import os\n","root_dir = \"/content/drive/My Drive/BS17B025_DDP/GPL/labelled_data\"\n","os.chdir(root_dir)\n","!pwd"],"metadata":{"id":"9EvcAmEO2-Bn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["folders = [f'_corpus{i}' for i in range(100)]\n","for folder in folders:\n","    path = os.path.join(root_dir,folder)\n","    os.makedirs(path)"],"metadata":{"id":"dJW6r7-Hs2G2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install datasets -q\n","!pip install huggingface_hub -q"],"metadata":{"id":"XCYLwylm2-Xt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from huggingface_hub import notebook_login\n","notebook_login()"],"metadata":{"id":"HAbxRcju3H1y"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from datasets import load_dataset\n","pubmed = load_dataset('ddp-iitm/pubmed_raw_text_v3', use_auth_token=True, streaming=True, split='train')"],"metadata":{"id":"WJ4TiOfW3NX7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import re\n","\n","pattern = r\"[^a-z, 0-9.()]\"\n","re_pattern = re.compile(pattern, re.I)\n","\n","def cleanup(example,idx):\n","    modified_example = {}\n","    modified_example['text'] = re.sub(re_pattern,\"\",example['text']).replace(\"  \", \" \").replace('\\t', ' ').replace('\\n', ' ').strip()\n","    modified_example['_id'] = str(idx)\n","    modified_example['title'] = ''\n","\n","    return modified_example"],"metadata":{"id":"cmbZmmXTF0wt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["pubmed = pubmed.map(cleanup, with_indices=True)"],"metadata":{"id":"42uxVZPZGclY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["pubmed.info"],"metadata":{"id":"sl7yKPRjJ3ww"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["pm = pubmed.take(3000)"],"metadata":{"id":"LDyGap4d_Mfo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["p = next(iter(pubmed))"],"metadata":{"id":"8aZDyUObGDE5"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Writing corpus"],"metadata":{"id":"OsxglCQIzap7"}},{"cell_type":"code","source":["import json\n","from tqdm import tqdm\n","\n","# Creating a folder to store the generated queries.\n","if not os.path.exists('corpus_data'):\n","    os.mkdir('corpus_data')\n","data_folder = os.path.join(root_dir, 'corpus_data')"],"metadata":{"id":"CvtL226MGFtQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data_folder"],"metadata":{"id":"8nThmf4EHFHz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import time\n","pbar = tqdm(total=100)\n","for i in range(10):\n","    pbar.update(10)\n","    time.sleep(.1)"],"metadata":{"id":"yjhsgsqxKzVQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["pm = pubmed.take(10)"],"metadata":{"id":"WGyobTnhIO2K"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def load_batches(generator, batch_size):\n","    buf = []\n","    id = 0\n","    pbar = tqdm(total=2340483)\n","    for example in generator:\n","        buf.append(example)\n","        if len(buf) == batch_size:\n","            write_to_jsonl(buf,id)\n","            buf = []\n","            id += 1\n","            pbar.update(len(buf))\n","    write_to_jsonl(buf,id)\n","\n","def write_to_jsonl(batch, id):\n","    corpus_file = f'corpus{id}.jsonl'\n","    corpus_file_path = os.path.join(data_folder, corpus_file)\n","    with open(corpus_file_path, 'w', encoding='utf-8') as f:\n","        for example in batch:\n","            json.dump(example,f)\n","            f.write('\\n')\n","    print(f'\\n Done writing {corpus_file}...')"],"metadata":{"id":"FSkEd-O0HMFI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["load_batches(pubmed, 10000)"],"metadata":{"id":"dcwEI9OzHDi9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["jsonl_files = [os.path.join(data_folder,f'corpus{i}.jsonl') for i in range(100)]"],"metadata":{"id":"UA9LtdIgSUJf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["outfile = os.path.join(data_folder, 'corpus1M-1.jsonl')\n","\n","with open(outfile, 'w') as newfile:\n","  for f in jsonl_Files:\n","      with open(f) as infile:\n","        contents = infile.read()\n","        newfile.write(contents)\n","        newfile.write('\\n')"],"metadata":{"id":"unr5YKTONV4e"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import subprocess\n","from ast import literal_eval\n","\n","def run(command):\n","    process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE)\n","    out, err = process.communicate()\n","    print(out.decode('utf-8').strip())\n","\n","print('# CPU')\n","run('cat /proc/cpuinfo | egrep -m 1 \"^model name\"')\n","run('cat /proc/cpuinfo | egrep -m 1 \"^cpu MHz\"')\n","run('cat /proc/cpuinfo | egrep -m 1 \"^cpu cores\"')\n","\n","print('# RAM')\n","run('cat /proc/meminfo | egrep \"^MemTotal\"')\n","\n","print('# GPU')\n","run('lspci | grep VGA')\n","\n","print('# OS')\n","run('uname -a')\n"],"metadata":{"id":"6_WHJP6kk9Ti"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Query generation"],"metadata":{"id":"IyZvnsdayZVC"}},{"cell_type":"code","source":["!pip install datasets -q\n","!pip install huggingface_hub -q\n","!pip install transformers -q\n","!pip install sentencepiece -q\n","!pip install psutil -q"],"metadata":{"id":"emywuKX4aUBt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import json\n","import time\n","from tqdm import tqdm\n","\n","import torch\n","from transformers import AutoTokenizer, AutoModelForSeq2SeqLM"],"metadata":{"id":"z_NbQmI0aUU-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Defining a query generation model and tokenizer ckpt\n","model_ckpt ='doc2query/msmarco-t5-base-v1'\n","\n","# Loading the tokenizer and the q-gen model\n","tokenizer = AutoTokenizer.from_pretrained(model_ckpt)\n","model = AutoModelForSeq2SeqLM.from_pretrained(model_ckpt)"],"metadata":{"id":"FWZb82XadREM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!nvidia-smi"],"metadata":{"id":"_5RMcgfQeJiG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["pm = pubmed.take(10)"],"metadata":{"id":"ox9tooM7bY9K"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["pbar = tqdm(iter(pm), total=10)\n","\n","for e in pbar:\n","    print('1')"],"metadata":{"id":"7q2GsNvXbLPb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os\n","import json\n","import datasets\n","from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n","from tqdm import tqdm\n","import torch, logging\n","\n","logger = logging.getLogger(__name__)\n","\n","\n","class QGenModel:\n","    def __init__(\n","            self,\n","            model_path: str,\n","            gen_prefix: str = \"\",\n","            use_fast: bool = True,\n","            device: str = None\n","        ):\n","        logger.info(\"Loading the tokenizer...\")\n","        self.tokenizer = AutoTokenizer.from_pretrained(model_path, use_fast=use_fast)\n","\n","        logger.info(\"Loading the model...\")\n","        self.model = AutoModelForSeq2SeqLM.from_pretrained(model_path)\n","\n","        self.gen_prefix = gen_prefix\n","        self.device = device or ('cuda' if torch.cuda.is_available() else 'cpu')\n","        logger.info(\"Use pytorch device: {}\".format(self.device))\n","        self.model = self.model.to(self.device)\n","\n","    def gen_query_embeddings(self,examples):\n","\n","        self.max_length = 64\n","        self.ques_per_passage = 3\n","\n","        encodings = self.tokenizer(\n","            examples['text'],\n","            padding=True,\n","            truncation=True,\n","            max_length = 512,\n","            return_tensors='pt'\n","        )\n","\n","        with torch.no_grad():\n","            outs = self.model.generate(\n","                input_ids=encodings['input_ids'].to(self.device),\n","                do_sample=True,\n","                max_length=self.max_length,\n","                #top_k=self.top_k\n","                #top_p=self.top_p,\n","                num_return_sequences=self.ques_per_passage\n","            )\n","\n","        return {\"embeddings\": {'outs':outs}}\n","\n","\n","    def generate(\n","            self,\n","            corpus: datasets.iterable_dataset.IterableDataset,\n","            num_examples:int,\n","            output_dir: str,\n","            top_p: int = 0.95,\n","            top_k: int = 25,\n","            max_length: int = 64,\n","            ques_per_passage: int = 3,\n","            prefix: str = \"QGen\",\n","            batch_size: int = 32,\n","            save: bool = True,\n","            save_after: int = 10000\n","        ):\n","        self.num_examples = num_examples\n","        self.output_dir = output_dir\n","        self.top_p = top_p,\n","        self.top_k = top_k,\n","        self.max_length = max_length\n","        self.ques_per_passage = ques_per_passage\n","        self.query_prefix = prefix\n","\n","        os.makedirs(self.output_dir, exist_ok = True)\n","\n","        logger.info(\"Starting to Generate {} Questions Per Passage using top-p (nucleus) sampling...\".format(ques_per_passage))\n","        logger.info(\"Params: top_p = {}\".format(top_p))\n","        logger.info(\"Params: top_k = {}\".format(top_k))\n","        logger.info(\"Params: max_length = {}\".format(max_length))\n","        logger.info(\"Params: ques_per_passage = {}\".format(ques_per_passage))\n","\n","        queries = corpus.map(self.gen_query_embeddings, batched=True, batch_size = batch_size, remove_columns=['text', 'title'])\n","\n","        # Decoding the queries\n","        queries = queries.map(self.decode_queries, batched=True, batch_size = batch_size, remove_columns=['embeddings'])\n","\n","        if save == False:\n","            return queries\n","\n","        self.save_in_batches(queries, save_after)\n","\n","\n","    def decode_queries(self,examples):\n","\n","        decoded_queries = self.tokenizer.batch_decode(\n","            examples['embeddings']['outs'],\n","            skip_special_tokens = True\n","        )\n","        idx_start = int(examples['_id'])*self.ques_per_passage\n","        query_ids = [f'{self.query_prefix}{id}' for id in range(idx_start,idx_start+self.ques_per_passage)]\n","        queries = [{\"_id\":id, \"text\":query} for id,query in zip(query_ids,decoded_queries)]\n","\n","        return {\"queries\":queries}\n","\n","    def save_in_batches(\n","        self,\n","        queries,\n","        save_after: int\n","        ):\n","\n","        buffer = []\n","        shard_num = 0\n","        pbar = tqdm(iter(queries), total = self.num_examples*self.ques_per_passage)\n","\n","        for example in pbar:\n","            buffer.append(example)\n","            if len(buffer) == save_after:\n","                self.write_to_jsonl(buffer, shard_num)\n","                buffer = []\n","                shard_num += 1\n","        if len(buffer) != 0:\n","            self.write_to_jsonl(buffer,shard_num)\n","\n","    def write_to_jsonl(self, buffer, shard_num):\n","\n","        queries_file = f'queries{shard_num}.jsonl'\n","        queries_file_path = os.path.join(self.output_dir, queries_file)\n","\n","        logger.info(f\"Saving {len(buffer)*self.ques_per_passage} Generated Queries to {queries_file}...\")\n","\n","        with open(queries_file_path, 'w', encoding='utf-8') as fOut:\n","            for example in buffer:\n","                queries = example['queries']\n","\n","                for line in queries:\n","                    json.dump(line,fOut)\n","                    fOut.write('\\n')\n","\n","        logger(f'Done writing {queries_file}...')\n"],"metadata":{"id":"K4C69Sv_m3Jc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["m = QGenModel('doc2query/msmarco-t5-base-v1')\n","p = pm.map(m.gen_query_embeddings, batched=True, batch_size=32)"],"metadata":{"id":"SlG7J1quDhS1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["pas = next(iter(pm))"],"metadata":{"id":"uQ4mk-NlEckR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["pas.keys()\n","len(pas['_id'])"],"metadata":{"id":"SiVy4cvnFjHT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["pa = m.gen_query_embeddings(pas)"],"metadata":{"id":"xXLVYI-GEwH2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["len(pa['embeddings'])"],"metadata":{"id":"EfYMUB9QE5q9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["next(iter(p))"],"metadata":{"id":"RH6__kWuD-aF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"Dh0rAZw3EhQr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os\n","import argparse\n","\n","\n","def qgen(\n","    corpus,\n","    num_examples,\n","    output_dir,\n","    generator_name_or_path=\"doc2query/msmarco-t5-base-v1\",\n","    ques_per_passage=3,\n","    bsz=32,\n","    qgen_prefix=\"QGen\",\n","    save = True,\n","    save_after = 100000\n","):\n","    #### question-generation model loading\n","    generator = QGenModel(generator_name_or_path)\n","\n","    #### Query-Generation using Nucleus Sampling (top_k=25, top_p=0.95) ####\n","    #### https://huggingface.co/blog/how-to-generate\n","    #### Prefix is required to seperate out synthetic queries and qrels from original\n","    prefix = qgen_prefix\n","\n","    #### Generating 3 questions per passage.\n","    #### Reminder the higher value might produce lots of duplicates\n","    #### Generate queries per passage from docs in corpus and save them in data_path\n","    try:\n","        generator.generate(\n","            corpus,\n","            num_examples = num_examples,\n","            output_dir=output_dir,\n","            ques_per_passage=ques_per_passage,\n","            prefix=prefix,\n","            batch_size=bsz,\n","            save = save,\n","            save_after = save_after\n","        )\n","    except RuntimeError as e:\n","        if \"CUDA out of memory\" in str(e):\n","            raise RuntimeError(\n","                f\"CUDA out of memory during query generation \"\n","                f\"(queries_per_passage: {ques_per_passage}, batch_size_generation: {bsz}). \"\n","                f\"Please try smaller `queries_per_passage` and/or `batch_size_generation`.\"\n","            )"],"metadata":{"id":"oo61nSYI9CeB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["query_folder = os.path.join(root_dir,'queries_data')\n","query_folder"],"metadata":{"id":"q-ujKUmd_unp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["qgen(pm,num_examples=3000,output_dir=query_folder)"],"metadata":{"id":"IKW1hLka9pMD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"lKR3qkfsCzQg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"83Xf4rcjCzmi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["if __name__ == \"__main__\":\n","    parser = argparse.ArgumentParser()\n","    parser.add_argument(\"--data_path\", required=True)\n","    parser.add_argument(\"--output_dir\", required=True)\n","    args = parser.parse_args()\n","    qgen(args.data_path, args.output_dir)\n"],"metadata":{"id":"iF84tMee9n4t"},"execution_count":null,"outputs":[]}]}